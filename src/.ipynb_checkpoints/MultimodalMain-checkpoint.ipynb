{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ce3338-182c-4d0d-815f-8eec476824d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 16:24:56.397339: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-14 16:24:56.407690: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760430296.420842    3783 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760430296.424606    3783 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-14 16:24:56.438218: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "sys.path.append('./utils')\n",
    "sys.path.append('./utils/APIs')\n",
    "from utils.common import save_model, write_to_file\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import timm\n",
    "import argparse\n",
    "from Config import config\n",
    "from Trainer import Trainer\n",
    "from Models.OTEModel import Model,MAMLModel\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from dataManagement.DatasetHelper import DatasetHelper\n",
    "from dataManagement.DatasetLoader import DatasetLoader\n",
    "from dataManagement.CustomDataset import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "781fd50f-9bb3-47ae-914a-7810f8e923a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "do_train = True\n",
    "do_test = True\n",
    "config.num_words_to_keep = 3000\n",
    "config.batch_size = 32\n",
    "config.num_words_x_doc = 100\n",
    "config.lr = 0.001\n",
    "config.momentum = 0.9\n",
    "config.wd = 1e-4\n",
    "config.load_model_path = '' # <---- change this, for example: './save_models/EDAF/xxxxxxx'\n",
    "config.fuse_model_type = 'EDAF'\n",
    "config.epoch = 20\n",
    "config.pre_train_epoch = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73378a10-461a-4f01-a490-3540e58644c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "----- [Loading]\n",
      "Train/val split: 2968/743\n"
     ]
    }
   ],
   "source": [
    "dataset_file_path = '../dataset/CornDataset/csv/train/train_data.csv' # <---- change this,\n",
    "data_loader = DatasetLoader()\n",
    "data_loader.load_data(dataset_file_path,False)\n",
    "train_data = data_loader.get_train_data()\n",
    "val_data = data_loader.get_val_data()\n",
    "\n",
    "data_helper = DatasetHelper(config.num_words_to_keep)\n",
    "train_y, val_y = data_helper.preprocess_labels(train_data, val_data)\n",
    "train_i, val_i = data_helper.preprocess_images(train_data.get_images(), val_data.get_images())\n",
    "train_t, val_t = data_helper.preprocess_texts(train_data.get_texts(), val_data.get_texts(), config.num_words_x_doc)\n",
    "\n",
    "# labels、images、text  set to data_geter\n",
    "data_loader.set_train_data(train_y, train_i, train_t)\n",
    "data_loader.set_val_data(val_y, val_i, val_t)\n",
    "\n",
    "# get CustomDataset (train and val)\n",
    "train_custom_dataset = CustomDataset(data_loader.get_train_data())\n",
    "val_custom_dataset = CustomDataset(data_loader.get_val_data())\n",
    "\n",
    "train_loader = DataLoader(train_custom_dataset, config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_custom_dataset, config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1262680c-3004-4ea8-8a35-1952049c97d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initilaztion\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5792737a-6e11-46e5-b4ef-d74f2b9d7361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backbone = Model(num_classes=config.num_labels, vocab_size=3000, embedding_size=512)\n",
    "model = MAMLModel(backbone, config.num_labels)\n",
    "trainer = Trainer(config, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a254be4-0998-485a-a62a-0776cab70169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PreTrain\n",
    "def preTrain():\n",
    "    task_lr = 0.01\n",
    "    inner_steps = 3\n",
    "    for e in range(config.pre_train_epoch):\n",
    "        print('-' * 20 + ' ' + 'PreTrain Epoch ' + str(e+1) + ' ' + '-' * 20)\n",
    "        trainer.preTrain(train_loader, e, task_lr, inner_steps)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ce90444-d574-49b7-8514-f7d92ca47872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "def train():\n",
    "    best_acc = 0\n",
    "    epoch = config.epoch\n",
    "    for e in range(epoch):\n",
    "        print('-' * 20 + ' ' + 'Epoch ' + str(e+1) + ' ' + '-' * 20)\n",
    "        trainer.train(train_loader,e)\n",
    "        test_acc = trainer.valid(val_loader,e)\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            save_path = './save_models'\n",
    "            save_model(save_path, config.fuse_model_type, model)\n",
    "            print('Update best model!')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4039ee07-6bad-4175-a79b-09c2cc9866fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "def test():\n",
    "    test_file_path = '../dataset/CornDataset/csv/test/test_data.csv' # <---- change this,\n",
    "    \n",
    "    data_loader = DatasetLoader()\n",
    "    data_loader.load_data(test_file_path,True)\n",
    "    test_data = data_loader.get_test_data()\n",
    "\n",
    "    data_helper = DatasetHelper(config.num_words_to_keep)\n",
    "    test_y = data_helper.preprocess_labels(test_data, None)\n",
    "    test_i = data_helper.preprocess_images(test_data.get_images(), None)\n",
    "    test_t = data_helper.preprocess_texts(test_data.get_texts(), None, config.num_words_x_doc)\n",
    "\n",
    "    data_loader.set_test_data(test_y, test_i, test_t)\n",
    "\n",
    "    # get CustomDataset\n",
    "    test_custom_dataset = CustomDataset(data_loader.get_test_data())\n",
    "    test_loader = DataLoader(test_custom_dataset, config.batch_size, shuffle=True)\n",
    "    \n",
    "    if config.load_model_path is not None:\n",
    "        print(\"model load successfully\")\n",
    "        model.load_state_dict(torch.load(config.load_model_path))\n",
    "\n",
    "    trainer.predict(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f20f670-9076-4fa1-85f3-f946b1b59665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# main\n",
    "if __name__ == \"__main__\":\n",
    "    if do_train:\n",
    "        # preTrain()\n",
    "        train()\n",
    "    \n",
    "    if do_test:\n",
    "        if config.load_model_path is None and not do_train:\n",
    "            print('Please enter the path load_model_path of the trained model or choose to add do_train arg')\n",
    "        else:\n",
    "            test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727861d6-f31b-43ac-a0c2-be3b795527da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4800271b-e260-4431-801d-48ef39aa4cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21b71f-360a-496c-91d2-167b81c813ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dab948-445e-42ac-92f9-b7d825bb0d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
